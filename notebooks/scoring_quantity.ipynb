{"cells":[{"cell_type":"code","source":["%pip install azure-cosmos"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47377505-e29f-408b-a780-6c50abc0c0cc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import functions as f\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql import Row\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql.functions import col, when\n\nfrom azure.cosmos import exceptions, CosmosClient, PartitionKey\nimport pandas as pd\nimport numpy as np\nimport scipy\nfrom scipy.stats import linregress\nimport os\nimport math\nimport time\n\ncosmosEndpoint = \"https://bhoojal-cosmos.documents.azure.com:443/\"\ncosmosMasterKey = \"0dDLs6jiq9oopPFt9oUkxx3Fima5EVJ6yEbPYIVAZY1oHqhyYxZ5mXcghgqsMvAabsVsBfi5Samh5V8onFc1NQ==\"\ncosmosDatabaseName = \"bhoojal_outlets\"\ncosmosContainerName = \"outlet\"\n# city data to be processed\ndbutils.widgets.text('city', '')\nquery_city = dbutils.widgets.get('city')\nprint(\"Starting notebook for city\", query_city)\n\n# Get Outlet from cosmos db\nclient = CosmosClient(cosmosEndpoint, cosmosMasterKey)\n\ndatabase = client.create_database_if_not_exists(id=cosmosDatabaseName)\n\ncontainer = database.create_container_if_not_exists(\n    id=cosmosContainerName, \n    partition_key=PartitionKey(path=\"/city\"),\n    offer_throughput=400\n)\n\ncontainer_depth = database.create_container_if_not_exists(\n    id=\"region_depth\", \n    partition_key=PartitionKey(path=\"/city\"),\n    offer_throughput=400\n)\n\ncontainer_rain = database.create_container_if_not_exists(\n    id=\"region_rain\", \n    partition_key=PartitionKey(path=\"/city\"),\n)\n\n# Configure Catalog Api to be used\nspark.conf.set(\"spark.sql.catalog.cosmosCatalog\", \"com.azure.cosmos.spark.CosmosCatalog\")\nspark.conf.set(\"spark.sql.catalog.cosmosCatalog.spark.cosmos.accountEndpoint\", cosmosEndpoint)\nspark.conf.set(\"spark.sql.catalog.cosmosCatalog.spark.cosmos.accountKey\", cosmosMasterKey)\n\n# build a view with all outlets\nall_outlets_cfg = {\n  \"spark.cosmos.accountEndpoint\" : cosmosEndpoint,\n  \"spark.cosmos.accountKey\" : cosmosMasterKey,\n  \"spark.cosmos.database\" : cosmosDatabaseName,\n  \"spark.cosmos.container\" : cosmosContainerName,\n  \"spark.cosmos.read.customQuery\" : \"SELECT * FROM c WHERE c.city = '\" + query_city + \"'\"\n}\n\ndf = spark.read.format(\"cosmos.oltp\").options(**all_outlets_cfg)\\\n .option(\"spark.cosmos.read.inferSchema.enabled\", \"true\")\\\n .load()\n\ndf.createOrReplaceTempView(\"CityOutlets\")\n\n# For every outlet, %sql\noutlets_df = spark.sql(\"SELECT * FROM CityOutlets\")\ncity_outlets = outlets_df.toPandas()\ncity_outlets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24a3fbfb-faca-4403-8ab9-10b6a7574749"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# This is a hack. Look away!\n# Using Cosmos Python SDK as Spark isn't supporting dynamic spatial queries. This routine can be moved to spark by creating a spatial query in native SQL.\nfor i in city_outlets.index:\n  distance_query = \"ST_DISTANCE(f.boundary, {\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\": [\" + str(city_outlets['location'][i]['coordinates'][0]) + \", \" + str(city_outlets['location'][i]['coordinates'][1]) + \"]})\"\n  depth_query = \"SELECT f.id,f.depth,f.scannedIn,\"+ distance_query +\" as distance FROM f WHERE \" + distance_query + \" < 600\"\n  #print(depth_query)\n  distance_query = \"ST_DISTANCE(f.boundary, {\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\": [\" + str(city_outlets['location'][i]['coordinates'][0]) + \", \" + str(city_outlets['location'][i]['coordinates'][1]) + \"]})\"\n  rain_query = \"SELECT f.id,f.rainFall,f.scannedIn,\"+ distance_query +\" as distance FROM f WHERE \" + distance_query + \" < 2000\"\n  print(rain_query)\n  \n  # Query depth data within range of outlet\n  depth_result = list(container_depth.query_items(\n    query=depth_query,\n    enable_cross_partition_query=True\n  ))\n  #print(len(depth_result), \"depth results found for outlet\", i)\n  \n  # Aggregate depths per quarter for the outlet\n  if len(depth_result) <= 0:\n    continue\n  depth_df = pd.DataFrame(depth_result, columns = ['scannedIn','depth'])\n  depth_df = depth_df.groupby('scannedIn', as_index=False).agg({\"depth\": \"mean\"})\n  print(len(depth_df), \"quarters of depth data found for outlet\", i)\n  \n  # Query rain data within range of outlet\n  rain_result = list(container_rain.query_items(\n    query=rain_query,\n    enable_cross_partition_query=True\n  ))\n  #print(len(rain_result), \"rain results found for outlet\", i)\n  \n  # Aggregate rain per quarter for the outlet\n  if len(rain_result) <= 0:\n    continue\n  rain_df = pd.DataFrame(rain_result, columns = ['scannedIn','rainFall'])\n  rain_df\n  rain_df = rain_df.groupby('scannedIn', as_index=False).agg({\"rainFall\": \"mean\"})\n  print(len(rain_df), \"quarters of rain data found for outlet\", i)\n  \n  if len(rain_df) != len(depth_df):\n    continue\n  \n  # Initialize X axis\n  x = pd.Series([1,2,3,4])\n  # Fetch Depth data for last 4 quarters\n  depth = pd.Series(depth_df['depth'])\n  # Fetch Rain data for last 4 quarters\n  rain = pd.Series(rain_df['rainFall'])\n\n  # Normalize depth and rain\n  depth = (depth - min(depth)) / (max(depth) - min(depth))\n  rain = (rain - min(rain)) / (max(rain) - min(rain))\n\n  # Calculate slope of the Depth metrics\n  depth_slope, intercept, r_value, p_value, std_err = linregress(x, depth)\n  depth_slope = depth_slope * -1\n  print(\"Depth slope:\",depth_slope) # Invert depth slope as higher values mean lesser water\n\n  # Calculate slope of the Rain metrics\n  rain_slope, intercept, r_value, p_value, std_err = linregress(x, rain)\n  print(\"Rain slope:\",rain_slope)\n\n  #Score is summation of both slopes\n  score = depth_slope + rain_slope\n  print(\"Score:\",score)\n  if  math.isnan(score):\n    print(\"Invalid score\")\n    continue\n  outlet_item = container.read_item(item=city_outlets['id'][i], partition_key=city_outlets['city'][i])\n  outlet_item['quantity_score'] = score\n  response = container.upsert_item(body=outlet_item)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5bba1b1-67b5-4b5d-af4f-f4542e033318"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"scoring_quantity","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{"city":{"nuid":"8fe09df3-1944-48e8-a596-1d6ad14b3e5a","currentValue":"pune","widgetInfo":{"widgetType":"text","name":"city","defaultValue":"","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":1291045346868416}},"nbformat":4,"nbformat_minor":0}
